{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#Enable API here: https://console.cloud.google.com/apis/api/earthengine.googleapis.com\n","import ee\n","\n","# Trigger the authentication flow.\n","ee.Authenticate()\n","\n","# Initialize the library.\n","ee.Initialize(project='ee-hungweipan2-1') #put your own project id\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZXj6xsCUuJS","outputId":"b9c225f4-b159-4b1c-c1fc-23feb06d6795","executionInfo":{"status":"ok","timestamp":1733565656455,"user_tz":420,"elapsed":2075,"user":{"displayName":"Ray Pan","userId":"18309358742742879224"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Gathering data\n","class FirePredictionModel:\n","    def __init__(self, roi_name, country_name):\n","        self.roi = ee.FeatureCollection(\"FAO/GAUL/2015/level1\") \\\n","                    .filter(ee.Filter.eq('ADM1_NAME', roi_name)) \\\n","                    .filter(ee.Filter.eq('ADM0_NAME', country_name))\n","\n","    def process_monthly_data(self, year, month):\n","        start_date = ee.Date.fromYMD(year, month, 1)\n","        end_date = start_date.advance(1, 'month')\n","\n","        # Fire data (label)\n","        fire = ee.ImageCollection('MODIS/061/MOD14A1') \\\n","            .filterBounds(self.roi) \\\n","            .filterDate(start_date, end_date) \\\n","            .max() \\\n","            .select('FireMask') \\\n","            .expression(\"(b('FireMask') == 7 || b('FireMask') == 8 || b('FireMask') == 9) ? 1 : 0\") \\\n","            .rename('FireOccurred') \\\n","            .toFloat()\n","\n","        # NDVI data\n","        ndvi = ee.ImageCollection('MODIS/061/MOD13A2') \\\n","            .filterBounds(self.roi) \\\n","            .filterDate(start_date, end_date) \\\n","            .max() \\\n","            .select('NDVI') \\\n","            .multiply(0.0001) \\\n","            .rename('NDVI')\n","\n","        # Weather data\n","        weather = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR') \\\n","            .filterBounds(self.roi) \\\n","            .filterDate(start_date, end_date)\n","\n","        max_temp = weather.select('temperature_2m').max().subtract(273.15).rename('MaxTemp')\n","        min_soil_moisture = weather.select('volumetric_soil_water_layer_1').min().rename('MinSoilMoisture')\n","\n","        max_wind_speed = weather.map(lambda img: img.expression(\n","            'sqrt(u**2 + v**2)', {\n","                'u': img.select('u_component_of_wind_10m'),\n","                'v': img.select('v_component_of_wind_10m')\n","            }\n","        ).rename('wind_speed')).max().rename('max_wind_speed')\n","\n","        # Combine image\n","        combined = fire \\\n","            .addBands(ndvi) \\\n","            .addBands(max_temp) \\\n","            .addBands(min_soil_moisture) \\\n","            .addBands(max_wind_speed)\n","        return combined\n","\n","    def collect_training_data(self, years, months, scale=1000, geometries=False):\n","        training_data = []\n","        for year in years:\n","            for month in months:\n","                image = self.process_monthly_data(year, month)\n","                samples = image.sample(\n","                    region=self.roi.geometry(),\n","                    scale=scale,\n","                    geometries=geometries\n","                )\n","                training_data.append(samples)\n","        return ee.FeatureCollection(training_data).flatten()\n","\n","\n","    def export_training_data(self, training_data, description, folder, file_format='CSV'):\n","        task = ee.batch.Export.table.toDrive(\n","        collection=training_data,\n","        description=description,\n","        folder=folder,\n","        fileFormat=file_format\n","        )\n","        task.start()\n","\n","# ------------------ 2015-2023 Training Data ------------------ #\n","# Initialize the model\n","model = FirePredictionModel(roi_name='Alberta', country_name='Canada')\n","\n","# Define years and months\n","years = list(range(2015, 2024))\n","months = list(range(5, 11))\n","\n","# Collect training data\n","training_data = model.collect_training_data(years, months)\n","\n","# Export training data to Google Drive\n","model.export_training_data(training_data, description='TrainingData2015_2023', folder = 'Training Data')\n","\n","print(\"Traning data (2015-2023) exporting...\")\n","\n","\n","\n","# ------------------ 2015-2024 Training Data ------------------ #\n","# Initialize the model\n","model = FirePredictionModel(roi_name='Alberta', country_name='Canada')\n","\n","# Define years and months\n","years = list(range(2015, 2025))\n","months = list(range(5, 11))\n","\n","# Collect training data\n","training_data = model.collect_training_data(years, months)\n","\n","# Export training data to Google Drive\n","model.export_training_data(training_data, description='TrainingData2015_2024', folder = 'Training Data')\n","\n","print(\"Traning data (2015-2024) exporting...\")\n","\n","# ------------------ 2024 Testing Data ------------------ #\n","# Initialize the model\n","model = FirePredictionModel(roi_name='Alberta', country_name='Canada')\n","\n","# Define years and months\n","years = list(range(2024, 2025))\n","months = list(range(5,11))\n","\n","# Collect training data\n","training_data = model.collect_training_data(years, months, scale=1000,geometries=True)\n","\n","\n","# Export training data to Google Drive\n","model.export_training_data(training_data, description='TestingData2024', folder = 'Training Data')\n","\n","print(\"Testing data (2024) exporting...\")\n","print(\"Check tasks status: https://code.earthengine.google.com/tasks\")\n"],"metadata":{"id":"CjsHzQO5UtCW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733559144957,"user_tz":420,"elapsed":3017,"user":{"displayName":"Ray Pan","userId":"18309358742742879224"}},"outputId":"e555d559-4397-4c26-ece7-394d4db52782"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Traning data (2015-2023) exporting...\n","Traning data (2015-2024) exporting...\n","Testing data (2024) exporting...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"sSIjgdo_lu61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Downsample\n","import pandas as pd\n","\n","def downsample_csv(input_csv, output_csv, downsample_factor=0.1):\n","    \"\"\"\n","    Downsample non-fire samples in the dataset to balance the data.\n","\n","    Parameters:\n","    - input_csv (str): Path to the input CSV file.\n","    - output_csv (str): Path to save the downsampled CSV file.\n","    - downsample_factor (float): Fraction of non-fire samples to retain (e.g., 0.1 means 10%).\n","\n","    Returns:\n","    - None: Saves the downsampled dataset to the specified output path.\n","    \"\"\"\n","    # Load the original CSV\n","    data = pd.read_csv(input_csv)\n","\n","    # Separate fire and non-fire samples\n","    fire_data = data[data['FireOccurred'] == 1]\n","    non_fire_data = data[data['FireOccurred'] == 0]\n","\n","    # Downsample non-fire samples\n","    non_fire_downsampled = non_fire_data.sample(frac=downsample_factor, random_state=42)\n","\n","    # Combine fire samples and downsampled non-fire samples\n","    combined_data = pd.concat([fire_data, non_fire_downsampled])\n","\n","    # Save the downsampled dataset\n","    combined_data.to_csv(output_csv, index=False)\n","    print(f\"Downsampled dataset saved to {output_csv}\")\n","\n","#Perform downsampling on the training dataset\n","#2015-2023 data\n","downsample_csv(\n","    input_csv='/content/drive/MyDrive/Training Data/TrainingData2015_2023.csv',\n","    output_csv='/content/drive/MyDrive/Training Data/TrainingData2015_2023_downsampled.csv',\n","    downsample_factor=0.1\n",")\n","\n","#2015-2024 data\n","downsample_csv(\n","    input_csv='/content/drive/MyDrive/Training Data/TrainingData2015_2024.csv',\n","    output_csv='/content/drive/MyDrive/Training Data/TrainingData2015_2024_downsampled.csv',\n","    downsample_factor=0.1\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmiUbWYnJMhG","executionInfo":{"status":"ok","timestamp":1733566012321,"user_tz":420,"elapsed":280662,"user":{"displayName":"Ray Pan","userId":"18309358742742879224"}},"outputId":"802eef18-9736-4e5b-81f1-c011ce9b0d78"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downsampled dataset saved to /content/drive/MyDrive/Training Data/TrainingData2015_2023_downsampled.csv\n","Downsampled dataset saved to /content/drive/MyDrive/Training Data/TrainingData2015_2024_downsampled.csv\n"]}]},{"cell_type":"code","source":["file_path_train = '/content/drive/MyDrive/Training Data/TrainingData2015_2023_downsampled.csv'\n","train_data = pd.read_csv(file_path_train)\n","\n","print(train_data.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78urjYnplwye","executionInfo":{"status":"ok","timestamp":1733566117007,"user_tz":420,"elapsed":7003,"user":{"displayName":"Ray Pan","userId":"18309358742742879224"}},"outputId":"7597ad41-37b7-4b3e-f9c3-b7064bc7d7a6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["  system:index  FireOccurred   MaxTemp  MinSoilMoisture    NDVI  \\\n","0      0_52814           1.0  21.22248         0.278349  0.5257   \n","1      0_52815           1.0  21.22248         0.278349  0.4591   \n","2      0_52816           1.0  21.22248         0.278349  0.4591   \n","3      0_52817           1.0  21.22248         0.278349  0.6517   \n","4      0_52818           1.0  21.22248         0.278349  0.6517   \n","\n","   max_wind_speed                                    .geo  \n","0         2.25131  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n","1         2.25131  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n","2         2.25131  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n","3         2.25131  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n","4         2.25131  {\"type\":\"MultiPoint\",\"coordinates\":[]}  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from joblib import dump\n","\n","\n","# ------------------ Model 1: 2015-2023 Data, Predicting 2024 ------------------ #\n","# Load data (2024)\n","file_path_test = '/content/drive/MyDrive/Training Data/TestingData2024.csv'\n","\n","feature_columns = ['NDVI', 'MaxTemp', 'MinSoilMoisture', 'max_wind_speed']\n","label_column = 'FireOccurred'\n","\n","test_data = pd.read_csv(file_path_test)\n","X_test = test_data[feature_columns]\n","y_test = test_data[label_column]\n","\n","\n","# Load training data (2015-2023)\n","file_path_train = '/content/drive/MyDrive/Training Data/TrainingData2015_2023_downsampled.csv'\n","train_data = pd.read_csv(file_path_train)\n","\n","feature_columns = ['NDVI', 'MaxTemp', 'MinSoilMoisture', 'max_wind_speed']\n","label_column = 'FireOccurred'\n","\n","X_train = train_data[feature_columns]\n","y_train = train_data[label_column]\n","\n","\n","# Train the Random Forest classifier\n","rf_classifier_1 = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n","rf_classifier_1.fit(X_train, y_train)\n","\n","# Save the model\n","model_file_path_1 = '/content/drive/MyDrive/Training Data/rf_fire_model_2015_2023_with_downsampling.joblib'\n","dump(rf_classifier_1, model_file_path_1)\n","print(f\"Model 1 saved to: {model_file_path_1}\")\n","\n","# Load 2024 data for prediction\n","file_path_test = '/content/drive/MyDrive/Training Data/TestingData2024.csv'\n","test_data = pd.read_csv(file_path_test)\n","\n","X_test = test_data[feature_columns]\n","y_test = test_data[label_column]\n","\n","# Predict on 2024 data\n","y_pred_1 = rf_classifier_1.predict(X_test)  # Binary output\n","y_pred_proba_1 = rf_classifier_1.predict_proba(X_test)[:, 1]  # Continuous output (Probability, between 1 and 0)\n","\n","# Export predictions for 2024 data\n","test_data['FireProbability'] = y_pred_proba_1\n","output_file_path_1 = '/content/drive/MyDrive/Training Data/TestingData2024_with_predictions.csv'\n","test_data.to_csv(output_file_path_1, index=False)\n","print(f\"Model 1 prediction saved to: {output_file_path_1}\")\n","\n","# ------------------ Model 2: 70/30 Split on 2015-2023 Data ------------------ #\n","# Reload training data (2015-2024)\n","file_path_train = '/content/drive/MyDrive/Training Data/TrainingData2015_2024_downsampled.csv'\n","data = pd.read_csv(file_path_train)\n","\n","feature_columns = ['NDVI', 'MaxTemp', 'MinSoilMoisture', 'max_wind_speed']\n","label_column = 'FireOccurred'\n","\n","train_data = pd.read_csv(file_path_train)\n","X_train = train_data[feature_columns]\n","y_train = train_data[label_column]\n","\n","# Split data into train (70%) and test (30%)\n","X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n","\n","# Train the Random Forest classifier on 70% of the data\n","rf_classifier_2 = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n","rf_classifier_2.fit(X_train, y_train_split)\n","\n","# Save the model\n","model_file_path_2 = '/content/drive/MyDrive/Training Data/rf_fire_model_70_30_split_with_downsampling.joblib'\n","dump(rf_classifier_2, model_file_path_2)\n","print(f\"Model 2 saved to: {model_file_path_2}\")\n","\n","# Predict on the 30% test set\n","y_pred_2 = rf_classifier_2.predict(X_test_split)\n","y_pred_proba_2 = rf_classifier_2.predict_proba(X_test_split)[:, 1]\n","\n","# Export predictions for the 30% test data\n","test_data_split = pd.DataFrame(X_test_split, columns=feature_columns)\n","test_data_split['Actual'] = y_test_split\n","test_data_split['Predicted'] = y_pred_2\n","test_data_split['FireProbability'] = y_pred_proba_2\n","\n","output_file_path_2 = '/content/drive/MyDrive/Training Data/TrainingData_70_30_split_with_predictions.csv'\n","test_data_split.to_csv(output_file_path_2, index=False)\n","print(f\"Model 2 prediction saved to: {output_file_path_2}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"llj5gYZhAkQ-","executionInfo":{"status":"error","timestamp":1733566034100,"user_tz":420,"elapsed":21783,"user":{"displayName":"Ray Pan","userId":"18309358742742879224"}},"outputId":"ee9219fe-53ff-4811-c742-a17f225e26e6"},"execution_count":6,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"\"['max_temp', 'min_soil_moisture'] not in index\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-66cd77b827ae>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['max_temp', 'min_soil_moisture'] not in index\""]}]},{"cell_type":"code","source":["!pip install rasterio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"JXAhCajsIiL4","executionInfo":{"status":"ok","timestamp":1733558432214,"user_tz":420,"elapsed":5586,"user":{"displayName":"Ray Pan","userId":"18309358742742879224"}},"outputId":"9d097d3e-9621-46d8-f86e-1b7633c2634b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rasterio\n","  Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n","Collecting affine (from rasterio)\n","  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.8.30)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n","Collecting cligj>=0.5 (from rasterio)\n","  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n","Collecting click-plugins (from rasterio)\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.0)\n","Downloading rasterio-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n","Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Installing collected packages: cligj, click-plugins, affine, rasterio\n","Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n"]}]},{"cell_type":"code","source":["# Convert CSV to Raster (GeoTIFF)\n","!pip install rasterio\n","import pandas as pd\n","import geopandas as gpd\n","from shapely.geometry import shape\n","from rasterio.features import rasterize\n","import rasterio\n","import numpy as np\n","import json\n","\n","# Load CSV\n","file_path = '/content/drive/MyDrive/Training Data/TestingData2024_fireseason_with_predictions.csv'\n","df = pd.read_csv(file_path)\n","\n","# Convert the .geo field to spatial points\n","df['geometry'] = df['.geo'].apply(lambda x: shape(json.loads(x)))  # Use json.loads to correctly parse the GeoJSON string\n","gdf = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")\n","\n","# Set the output GeoTIFF file name\n","output_tiff_path = '/content/drive/MyDrive/Training Data/TestingData2024_fireseason_with_predictions.tif'\n","\n","# Set resolution to 1000 meters (approximately 0.009 degrees)\n","resolution = 0.009  # Resolution (unit: degrees)\n","\n","# Create rasterized data\n","bounds = gdf.total_bounds  # Get bounds (minx, miny, maxx, maxy)\n","transform = rasterio.transform.from_bounds(*bounds,\n","                                           width=int((bounds[2]-bounds[0])/resolution),\n","                                           height=int((bounds[3]-bounds[1])/resolution))\n","\n","# Set the output image size\n","out_shape = (\n","    int((bounds[3] - bounds[1]) / resolution),  # Number of rows\n","    int((bounds[2] - bounds[0]) / resolution)   # Number of columns\n",")\n","\n","# Rasterize\n","raster = rasterize(\n","    ((geom, value) for geom, value in zip(gdf.geometry, gdf['FireProbability'])),\n","    out_shape=out_shape,\n","    transform=transform,\n","    fill=0,\n","    all_touched=True,\n","    dtype='float32'\n",")\n","\n","# Save as GeoTIFF\n","with rasterio.open(\n","    output_tiff_path,\n","    'w',\n","    driver='GTiff',\n","    height=raster.shape[0],\n","    width=raster.shape[1],\n","    count=1,\n","    dtype='float32',\n","    crs=\"EPSG:4326\",\n","    transform=transform,\n",") as dst:\n","    dst.write(raster, 1)\n","\n","print(f\"GeoTIFF saved at: {output_tiff_path}\")\n"],"metadata":{"id":"FziV2f8iCLkj"},"execution_count":null,"outputs":[]}]}